{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание по курсу <br>«Линейная алгебра и приложения в многомерной статистике»\n",
    "\n",
    "*Алла Тамбовцева*\n",
    "\n",
    "\n",
    "## Часть 1 (10 баллов)\n",
    "\n",
    "В этой части предлагается продолжить работу с файлом `flats_cian_upd.csv` с занятий, только кластеризовать теперь нужно не квартиры и станции метро, а районы Москвы. Необходимо понять, на какие группы можно разделить районы Москвы с точки зрения стоимости и качества недвижимости. \n",
    "\n",
    "Импортируйте необходимые библиотеки и загрузите в датафрейм данные из файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1 (1 балл)\n",
    "\n",
    "Сгруппируйте строки в датафрейме по названию района (`district`), выберите столбцы с ценой квартиры, площадью, количеством комнат и расстоянием до метро, вычислите медиану по всем выбранным столбцам в каждой группе. Сохраните результат в датафрейм. \n",
    "\n",
    "Для самопроверки: у вас должен получиться датафрейм из 116 строк и 4 столбцов с медианными значениями показателей в каждом районе, названия районов – по строкам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2 (1 балл)\n",
    "\n",
    "Выполните нормировку данных (стандартизацию) и выполните кластеризацию, выбрав метод Варда в качестве метода агрегирования. Постройте дендрограмму. Можно ли выделить более двух кластеров районов таким образом, чтобы в каждом кластере было более одного наблюдения?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3 (2 балла)\n",
    "\n",
    "При любом ответе на вопрос предыдущей задачи выделите три кластера районов и сохраните метки кластеров в датафрейм (для определенности пусть будет столбец `ward`). Выведите число наблюдений в каждом кластере. Выведите названия районов в тех кластерах, где число наблюдений менее 10. Оправданы ли содержательно такие маленькие кластеры?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 4 (1 балл)\n",
    "\n",
    "Повторите действия из задачи 1, только вместо медианы по выбранным столбцам посчитайте среднее. У вас должен получиться датафрейм из 116 строк и 4 столбцов со средними значениями показателей в каждом районе, названия районов – по строкам.\n",
    "\n",
    "Выполните нормировку данных (стандартизацию) и выполните кластеризацию, выбрав метод Варда в качестве метода агрегирования. Постройте дендрограмму. Можно ли выделить более двух кластеров районов таким образом, чтобы в каждом кластере было более одного наблюдения?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 5 (2 балла)\n",
    "\n",
    "При любом ответе на вопрос предыдущей задачи выделите четыре кластера районов и сохраните метки кластеров в датафрейм (для определенности пусть будет столбец `ward`). Выведите описательные статистики для цены квартиры, площади и расстояния до метро. Можно ли считать полученное деление на группы содержательно оправданным и логичным? Если есть необходимость, объедините наблюдения в более крупные группы, но чтобы число кластеров было больше двух.\n",
    "\n",
    "**NB.** Оставьте метки кластеров *числовыми* (целые числа от 0 и далее), так нужно для последнего задания этой части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 6 (1 балл)\n",
    "\n",
    "Используя выбранное число кластеров, запустите кластеризацию методом k-means. Сохраните метки кластеров в датафрейм (для определенности пусть будет столбец `kmeans`).\n",
    "\n",
    "**NB.** Оставьте метки кластеров *числовыми* (целые числа от 0 и далее), так нужно для последнего задания этой части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 7 (2 балла)\n",
    "\n",
    "Загрузите геоданные из [файла](https://raw.githubusercontent.com/allatambov/LinStat25/refs/heads/main/%D0%9C%D0%BE%D1%81%D0%BA%D0%B2%D0%B0_Moscow.geojson) (как мы делали на занятии). Ниже приведен пример кода для объединения датафрейма с данными по районам и геодатафрейма с границами районов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_geo: геодатафрейм из файла geojson\n",
    "# data: ваш датафрейм с добавленными метками кластеров\n",
    "\n",
    "final = df_geo.merge(data, on=\"district\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы правильно объединили датафреймы, код ниже построит вам карту, где районы с высокой средней площадью квартиры (`square`) закрашены темно-красным цветом, с низкой – бледно-оранжевым (палитра `OrRd`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.plot(column='square', cmap='OrRd', legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя логику кода выше:\n",
    "\n",
    "* Постройте карту Москвы и раскрасьте районы так, чтобы цвет заливки района означал принадлежность к определенной группе согласно кластеризации методом Варда.\n",
    "\n",
    "* Постройте карту Москвы и раскрасьте районы так, чтобы цвет заливки района означал принадлежность к определенной группе согласно кластеризации k-means.\n",
    "\n",
    "Какая кластеризация кажется более удачной с точки зрения географического расположения районов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнение.** Можете выбрать другую цветовую палитру [отсюда](https://matplotlib.org/stable/users/explain/colors/colormaps.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2 (5 баллов)\n",
    "\n",
    "В этой части предлагается продолжить работу с результатами опроса по сказке «Не покидай...», только файл Excel более новый, в него добавлены результаты опроса нынешнего 1 курса (опрос 15). Файл `NPK25_share_upd.xlsx` можно скачать по [ссылке](https://disk.yandex.ru/i/MLwJQkcBFspHrA).\n",
    "\n",
    "Так как при большом количестве бинарных столбцов кластеризация не всегда проходит успешно (группы формируются в любом случае, но не всегда четкие), кластеризовать респондентов мы будем не по исходным данным – 10 столбцов с выбором/не-выбором героев по текстовому описанию – а по двум главным компонентам, которые получим в результате снижения размерности.\n",
    "\n",
    "Для снижения размерности в случае количественных данных обычно используется метод главных компонент. Для качественных данных он не подойдет, поэтому вместо него выберем многомерное шкалирование (*multidimensional scaling*). Идея многомерного шкалирования несильно отличается от идеи метода главных компонент, из пространства большой размерности переходим в пространство меньшей размерности, только вместо ковариации переменных рассматривается сходство наблюдений. Если в методе главных компонент выполняется разложение ковариационной матрицы, то здесь мы имеем дело с разложением матрицы сходства, которая получается на основе матрицы расстояний между наблюдениями. Удобство метода в том, что он достаточно гибкий – можно использовать метрики, подходящие для конкретного типа данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1 (0.5 балла)\n",
    "\n",
    "Ниже написан готовый код для загрузки данных с первой страницы файла (выбор по текстовому описанию) и объединения «голосования» за тематически близких героев. Также создается список `heroes` для удобства обращения к столбцам с именами героев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npk = pd.read_excel(\"NPK25_share_upd.xlsx\")\n",
    "\n",
    "npk[\"Давиль Оттилия\"] = npk[\"Давиль\"] + npk[\"Оттилия\"]\n",
    "npk[\"Жак Марта\"] = npk[\"Жак\"] + npk[\"Марта\"]\n",
    "\n",
    "heroes = ['Теодор', 'Флора', 'Альбина', 'Патрик', 'Пенапью', \n",
    "          'Марселла', 'Жак Марта', 'Давиль Оттилия']\n",
    "\n",
    "npk[heroes].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите строки, соответствующие студентам профиля *политология и управление*, и сохраните их в датафрейм `polit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2 (1.5 балла)\n",
    "\n",
    "Чтобы выполнить снижение размерности с помощью многомерного шкалирования, нам понадобится матрица расстояний. В модуле `scipy.spatial.distance` есть разные функции для вычисления расстояний, включая те, которые мы обсуждали для качественных данных: \n",
    "\n",
    "* расстояние Хэмминга;\n",
    "* основанное на мере сходства Дайса;\n",
    "* основанное на мере сходства Жаккара.\n",
    "\n",
    "Ниже написан готовый код, который позволяет сформировать матрицу расстояний Хэмминга для всех строк в датафрейме `choices`, то есть оценить расстояния между всеми респондентами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.spatial.distance import hamming, dice, jaccard, squareform\n",
    "\n",
    "# выбираем только столбцы с выбором героев\n",
    "choices = polit[heroes]\n",
    "\n",
    "# создаем пустой список для уникальных расстояний\n",
    "unique_dist = []\n",
    "\n",
    "# combinations() возвращает уникальные пары строк датафрейма choices\n",
    "# считаем расстояния между всеми парами через hamming()\n",
    "\n",
    "for pair in combinations(choices.values, 2):\n",
    "    unique_dist.append(hamming(pair[0], pair[1]))\n",
    "    \n",
    "# записываем расстояния в матрицу\n",
    "# см практикум cluster00\n",
    "    \n",
    "D = squareform(unique_dist)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое расстояние (Хэмминга, на основе меры Жаккара, меры Дайса) подойдет, если мы хотим, чтобы совпадения вида (1, 1) учитывались с большим весом, а совпадения вида (0, 0) игнорировались? \n",
    "\n",
    "Обоснуйте свой ответ и объясните, почему в контексте работы с имеющимися данными такой выбор логичен.\n",
    "\n",
    "При необходимости скорректируйте код выше, чтобы получить матрицу расстояний `D` с использованием корректной метрики. Все необходимые функции для вычисления расстояний уже импортированы во второй строке кода выше, ваша задача выбрать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3 (1 балл)\n",
    "\n",
    "Ниже приведен готовый код для реализации многомерного шкалирования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "mds = MDS(n_components=2, \n",
    "          dissimilarity='precomputed', \n",
    "          random_state=89)\n",
    "\n",
    "result = mds.fit_transform(D)\n",
    "result_df = pd.DataFrame(result, columns = [\"D1\", \"D2\"])\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пояснения:\n",
    "\n",
    "* на выходе хотим получить две главных компоненты, отсюда `n_components=2`;\n",
    "* вместо базового расстояния Евклида подаем готовую матрицу расстояний, `dissimilarity ='precomputed'`;\n",
    "* в алгоритме используется случайность, для гарантии одинаковых результатов фиксируем стартовую точку алгоритма `random_state=89`.\n",
    "\n",
    "Применяем алгоритм с выставленными параметрами к матрице `D`, превращаем для наглядности результат в датафрейм. \n",
    "\n",
    "Столбцы `D1` и `D2` – числовые индексы, которые отражают предпочтения респондентов вместо исходных восьми столбцов с выбором/не-выбором героев. Как именно отражают – можно добавить столбцы `D1` и `D2` в исходный датафрейм `choices`, посмотреть, у каких респондентов высокие/низкие значения этих индексов и подумать о содержательной интерпретации этих индексов.\n",
    "\n",
    "В интерпретацию углубляться не будем, попробуем кластеризовать респондентов в пространстве сниженной размерности – вместо кластеризации по 8 столбцам выполним кластеризацию по новым индексам `D1` и `D2`. Построим на диаграмму рассеивания между ними:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(result_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно ли заключить по диаграмме рассеивания, что респонденты образуют четкие группы? Если да, то сколько?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 4 (2 балла)\n",
    "\n",
    "Выполните кластеризацию респондентов на основе столбцов в датафрейме `result_df` без шкалирования данных (`D1` и `D2` в одинаковой шкале), используя евклидово расстояние и метод средней связи. Постройте дендрограмму и выделите разумное число кластеров больше 2. \n",
    "\n",
    "Сохраните метки кластеров в датафрейм `choices`. Сгруппируйте строки по меткам кластеров и определите состав кластеров – сколько респондентов в каждом кластере голосует за героев из списка `heroes`. \n",
    "\n",
    "Можете придумать творческие говорящие названия полученным кластерам :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
